[Under construction]
In case of Llama2 model, you need to specify do_sampling in llm_query_helper.py 

Finetuning ChatGPT and Llama2:
https://colab.research.google.com/drive/1efaeCj3tAxOXl8fn5pLT9j2PUR73UdAm?usp=sharing
