[Under construction]
In case of Llama2 model, you need to specify do_sampling in llm_query_helper.py 

Finetuning ChatGPT and Llama2:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1efaeCj3tAxOXl8fn5pLT9j2PUR73UdAm?usp=sharing)
