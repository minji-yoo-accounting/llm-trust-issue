[Under construction]
In case of Llama2 model, you need to specify do_sampling in llm_query_helper.py 

Finetuning ChatGPT and Llama2:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1efaeCj3tAxOXl8fn5pLT9j2PUR73UdAm?usp=sharing)

Finetuning RoBERTa and FinBERT:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lVfRK2COCHEz1gdQ2fodA31wkNwJjIgL?usp=sharing)

Testing Finetuned models:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uQ9jc4SlK_zG892CMEY6Bvu9CZwZKrNb?usp=sharing)

Finetuned models can be found here:[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Profile-yellow)](https://huggingface.co/minjiyoo)
